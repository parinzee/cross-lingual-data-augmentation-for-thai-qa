{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Pre Augmentation Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from bs4 import BeautifulSoup\n",
    "from pythainlp.util import normalize\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset iapp_wiki_qa_squad (/Users/parinzee/.cache/huggingface/datasets/iapp_wiki_qa_squad/iapp_wiki_qa_squad/1.0.0/c1455d806e5a66ca9ee5c03b4aeaeaef4410afca6263c0bfb440ff1db28e20c3)\n",
      "100%|██████████| 3/3 [00:00<00:00, 484.97it/s]\n",
      "Found cached dataset thaiqa_squad (/Users/parinzee/.cache/huggingface/datasets/thaiqa_squad/thaiqa_squad/1.0.0/fce14864b511d48464540780f328f4b415746b63f2fd934ad0b06c3eead7787b)\n",
      "100%|██████████| 2/2 [00:00<00:00, 351.37it/s]\n",
      "Found cached dataset xquad (/Users/parinzee/.cache/huggingface/datasets/xquad/xquad.th/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n",
      "100%|██████████| 1/1 [00:00<00:00, 499.02it/s]\n",
      "Found cached dataset tydiqa-goldp (/Users/parinzee/.cache/huggingface/datasets/khalidalt___tydiqa-goldp/thai/1.1.0/c0ba4613293c9a8e7cdc684809f0b2a520a66f38b23af4af5c09ea55e2b972f0)\n",
      "100%|██████████| 2/2 [00:00<00:00, 222.07it/s]\n"
     ]
    }
   ],
   "source": [
    "iapp    = load_dataset(\"iapp_wiki_qa_squad\")\n",
    "thaiqa  = load_dataset(\"thaiqa_squad\")\n",
    "xquad   = load_dataset(\"xquad\", \"xquad.th\")\n",
    "tydiqa = load_dataset(\"khalidalt/tydiqa-goldp\", \"thai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all splits of each dataset\n",
    "def merge_dataset_splits(dataset):\n",
    "    splits = list(dataset.keys())\n",
    "    if len(splits) == 1:\n",
    "        return dataset[splits[0]]\n",
    "    else:\n",
    "        return concatenate_datasets([dataset[split] for split in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "iapp = merge_dataset_splits(iapp).to_pandas()\n",
    "thaiqa = merge_dataset_splits(thaiqa).to_pandas()\n",
    "xquad = merge_dataset_splits(xquad).to_pandas()\n",
    "tydiqa = merge_dataset_splits(tydiqa).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "iapp = iapp[['question', 'context', 'answers']]\n",
    "thaiqa = thaiqa[['question', 'context', 'answers']]\n",
    "xquad = xquad[['question', 'context', 'answers']]\n",
    "tydiqa = tydiqa.rename(columns={'passage_text': 'context', \"question_text\": \"question\"})[['question', 'context', 'answers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets require more processing to make them all in the correct format\n",
    "def clean_text(text):\n",
    "    # Remove html tags\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Remove semicolons\n",
    "    text = re.sub(r';', '', text)\n",
    "\n",
    "    # Remove empty parenthesis and parenthesis with only whitespace inside\n",
    "    text = re.sub(r'\\(\\s*\\)', '', text)\n",
    "    text = re.sub(r'\\(;\\s*\"(\\w+)\"\\)', r'(\"\\1\")', text)\n",
    "\n",
    "    # Remove reference citations for example [2]:7 or [9]:5 (present in tydiqa)\n",
    "    text = re.sub(r'\\[\\d+\\]:\\d+', '', text)\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "\n",
    "    # Remove more than one whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Strip text inside of parenthesis\n",
    "    text = re.sub(r'\\(\\s*([^)]*)\\)', r'(\\1)', text)\n",
    "\n",
    "    # Remove em dashes\n",
    "    text = re.sub(u\"\\u2014\", \"\", text)\n",
    "\n",
    "    text = normalize(text)\n",
    "    return text\n",
    "\n",
    "def get_offset_begin_position(cleaned_context, answers_text, answer_begin_positions):\n",
    "    new_answer_begin_positions = []\n",
    "\n",
    "    try:\n",
    "        for answer_text, answer_begin_position in zip(answers_text, answer_begin_positions):\n",
    "            # Find all all instances of the answer in cleaned_context\n",
    "            possible_answer_begin_positions = [index for index in range(len(cleaned_context)) if cleaned_context.find(answer_text, index)]\n",
    "\n",
    "            # If len is 1, then we can just use the begin position of the answer in the cleaned_context\n",
    "            if len(possible_answer_begin_positions) == 1:\n",
    "                new_answer_begin_positions.append(possible_answer_begin_positions[0])\n",
    "            \n",
    "            # If len is 0, then we progressively remove the last character of the answer until we find a match\n",
    "            elif len(possible_answer_begin_positions) == 0:\n",
    "                while len(possible_answer_begin_positions) == 0:\n",
    "                    possible_answer_begin_positions =  [index for index in range(len(cleaned_context)) if cleaned_context.find(answer_text, index)]\n",
    "                    answer_text = answer_text[:-1]\n",
    "                    if len(answer_text) == 0:\n",
    "                        raise Exception(\"Answer not found in context\")\n",
    "                \n",
    "                # If len is 1, then we can just use the begin position of the answer in the cleaned_context\n",
    "                if len(possible_answer_begin_positions) == 1:\n",
    "                    new_answer_begin_positions.append(possible_answer_begin_positions[0])\n",
    "                elif len(possible_answer_begin_positions) > 1:\n",
    "                    # Take the index closest to the original answer begin position\n",
    "                    new_answer_begin_positions.append(min(possible_answer_begin_positions, key=lambda x: abs(x - answer_begin_position)))\n",
    "    except:\n",
    "        print(\"Error with answer: \", answer_text)\n",
    "        print(\"Error with context: \", cleaned_context)\n",
    "        print(\"Error with answer begin position: \", answer_begin_position)\n",
    "        raise\n",
    "    \n",
    "    return new_answer_begin_positions\n",
    "\n",
    "def process_row(row, answer_text_key, answer_start_key):\n",
    "    # Normalize the text\n",
    "    new_row = deepcopy(row)\n",
    "    new_row[\"context\"] = clean_text(row[\"context\"])\n",
    "    new_row[\"question\"] = clean_text(row[\"question\"])\n",
    "\n",
    "    new_row[\"answers\"] = {}\n",
    "    new_row[\"answers\"][\"text\"] = [clean_text(x) for x in row[\"answers\"][answer_text_key]]\n",
    "\n",
    "    # Reindex the dataset\n",
    "    new_row[\"answers\"][\"answer_start\"] = get_offset_begin_position(new_row[\"context\"], new_row[\"answers\"][\"text\"], row[\"answers\"][answer_start_key])\n",
    "    new_row[\"answers\"][\"answer_end\"] = [x + len(y) for x, y in zip(new_row[\"answers\"][\"answer_start\"], new_row[\"answers\"][\"text\"])]\n",
    "\n",
    "    return new_row\n",
    "\n",
    "def sanity_check(datasets):\n",
    "    # Match keys\n",
    "    for dataset in tqdm(datasets):\n",
    "        assert list(dataset.columns) == list(datasets[0].columns)\n",
    "        assert dataset['answers'][0].keys() == datasets[0]['answers'][0].keys()\n",
    "    \n",
    "    print(\"All Keys Matched...\")\n",
    "\n",
    "    # Check theortical answers vs index\n",
    "    for dataset in datasets:\n",
    "        for _, row in tqdm(list(dataset.iterrows())):\n",
    "            for text, begin, end in zip(row[\"answers\"]['text'], row[\"answers\"]['answer_start'], row[\"answers\"]['answer_end']):\n",
    "                assert text == row['context'][begin:end], f\"Theoretical Answer: {text} | Indexed: {row['context'][begin:end]} | Context: {row['context']}\"\n",
    "    \n",
    "    print(\"Theortical Answers Matched...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/h98880vs70721mv159jzwy6h0000gn/T/ipykernel_23987/3248794723.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'lxml')\n",
      "/var/folders/6_/h98880vs70721mv159jzwy6h0000gn/T/ipykernel_23987/3248794723.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'lxml')\n",
      "/var/folders/6_/h98880vs70721mv159jzwy6h0000gn/T/ipykernel_23987/3248794723.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'lxml')\n",
      "/var/folders/6_/h98880vs70721mv159jzwy6h0000gn/T/ipykernel_23987/3248794723.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'lxml')\n"
     ]
    }
   ],
   "source": [
    "iapp = iapp.apply(lambda x: process_row(x, \"text\", \"answer_start\"), axis=1)\n",
    "thaiqa = thaiqa.apply(lambda x: process_row(x, \"answer\", \"answer_begin_position\"), axis=1)\n",
    "xquad = xquad.apply(lambda x: process_row(x, \"text\", \"answer_start\"), axis=1)\n",
    "tydiqa = tydiqa.apply(lambda x: process_row(x, \"text\", \"start_byte\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 2888.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Keys Matched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7242/7242 [00:00<00:00, 84331.84it/s]\n",
      "100%|██████████| 4074/4074 [00:00<00:00, 86065.82it/s]\n",
      "100%|██████████| 1190/1190 [00:00<00:00, 84205.92it/s]\n",
      "100%|██████████| 4579/4579 [00:00<00:00, 85255.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theortical Answers Matched...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sanity_check([iapp, thaiqa, xquad, tydiqa])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "iapp[\"source\"] = \"iapp\"\n",
    "thaiqa[\"source\"] = \"thaiqa\"\n",
    "xquad[\"source\"] = \"xquad\"\n",
    "tydiqa[\"source\"] = \"tydiqa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>พัทธ์ธีรา ศรุติพงศ์โภคิน เกิดวันที่เท่าไร</td>\n",
       "      <td>พัทธ์ธีรา ศรุติพงศ์โภคิน (เกิด 3 ธันวาคม พ.ศ. ...</td>\n",
       "      <td>{'text': ['3 ธันวาคม พ.ศ. 2533'], 'answer_star...</td>\n",
       "      <td>iapp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>พัทธ์ธีรา ศรุติพงศ์โภคิน มีฃื่อเล่นว่าอะไร</td>\n",
       "      <td>พัทธ์ธีรา ศรุติพงศ์โภคิน (เกิด 3 ธันวาคม พ.ศ. ...</td>\n",
       "      <td>{'text': ['อร'], 'answer_start': [], 'answer_e...</td>\n",
       "      <td>iapp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>พัทธ์ธีรา ศรุติพงศ์โภคิน ทำอาชีพอะไร</td>\n",
       "      <td>พัทธ์ธีรา ศรุติพงศ์โภคิน (เกิด 3 ธันวาคม พ.ศ. ...</td>\n",
       "      <td>{'text': ['นักแสดงหญิงชาวไทย'], 'answer_start'...</td>\n",
       "      <td>iapp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>พัทธ์ธีรา ศรุติพงศ์โภคิน จบการศึกษาจากประเทศอะไร</td>\n",
       "      <td>พัทธ์ธีรา ศรุติพงศ์โภคิน (เกิด 3 ธันวาคม พ.ศ. ...</td>\n",
       "      <td>{'text': ['ประเทศนิวซีแลนด์'], 'answer_start':...</td>\n",
       "      <td>iapp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>บิดาของคลีโอพัตราเป็นใคร</td>\n",
       "      <td>คลีโอพัตราที่ 7 ฟิโลพาเธอร์ (กรีก: Κλεοπάτρα θ...</td>\n",
       "      <td>{'text': ['ทอเลมีที่ 12 ออเลติส'], 'answer_sta...</td>\n",
       "      <td>iapp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17080</th>\n",
       "      <td>หนังสือการ์ตูนชานะ นักรบเนตรอัคคี มีกี่เล่ม?</td>\n",
       "      <td>นิยาย ชานะ นักรบเนตรอัคคี แต่งโดย ยาชิจิโร ทาค...</td>\n",
       "      <td>{'text': ['22', '26'], 'answer_start': [], 'an...</td>\n",
       "      <td>tydiqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17081</th>\n",
       "      <td>ไบโอช็อก อินฟินิต เปิดตัวครั้งแรกเมื่อไหร่?</td>\n",
       "      <td>ไบโอช็อก อินฟินิต (English: BioShock Infinite)...</td>\n",
       "      <td>{'text': ['26 มีนาคม พ.ศ. 2556', '26 มีนาคม พ....</td>\n",
       "      <td>tydiqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17082</th>\n",
       "      <td>ยู ซึง-โฮ เริ่มเข้าวงการบันเทิงเมื่อไหร่?</td>\n",
       "      <td>ยู ซึง-โฮเดบิวต์เมื่อปี 1999 กับผลงานโฆษณาของ ...</td>\n",
       "      <td>{'text': ['ปี 1999', '1999'], 'answer_start': ...</td>\n",
       "      <td>tydiqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17083</th>\n",
       "      <td>นภัทร อินทร์ใจเอื้อมีมารดาชื่อว่าอะไร?</td>\n",
       "      <td>กันเกิดเมื่อวันที่ 23 ตุลาคม พ.ศ. 2533 จังหวัด...</td>\n",
       "      <td>{'text': ['นางวรรณา อินทร์ใจเอื้อ', 'นางวรรณา ...</td>\n",
       "      <td>tydiqa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17084</th>\n",
       "      <td>หม่อมราชวงศ์สุขุมพันธุ์ บริพัตร เกิดเมื่อไหร่?</td>\n",
       "      <td>รองศาสตราจารย์ หม่อมราชวงศ์สุขุมพันธุ์ บริพัตร...</td>\n",
       "      <td>{'text': ['22 กันยายน 2495', '22 กันยายน 2495'...</td>\n",
       "      <td>tydiqa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17085 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question   \n",
       "0             พัทธ์ธีรา ศรุติพงศ์โภคิน เกิดวันที่เท่าไร  \\\n",
       "1            พัทธ์ธีรา ศรุติพงศ์โภคิน มีฃื่อเล่นว่าอะไร   \n",
       "2                  พัทธ์ธีรา ศรุติพงศ์โภคิน ทำอาชีพอะไร   \n",
       "3      พัทธ์ธีรา ศรุติพงศ์โภคิน จบการศึกษาจากประเทศอะไร   \n",
       "4                              บิดาของคลีโอพัตราเป็นใคร   \n",
       "...                                                 ...   \n",
       "17080      หนังสือการ์ตูนชานะ นักรบเนตรอัคคี มีกี่เล่ม?   \n",
       "17081       ไบโอช็อก อินฟินิต เปิดตัวครั้งแรกเมื่อไหร่?   \n",
       "17082         ยู ซึง-โฮ เริ่มเข้าวงการบันเทิงเมื่อไหร่?   \n",
       "17083            นภัทร อินทร์ใจเอื้อมีมารดาชื่อว่าอะไร?   \n",
       "17084    หม่อมราชวงศ์สุขุมพันธุ์ บริพัตร เกิดเมื่อไหร่?   \n",
       "\n",
       "                                                 context   \n",
       "0      พัทธ์ธีรา ศรุติพงศ์โภคิน (เกิด 3 ธันวาคม พ.ศ. ...  \\\n",
       "1      พัทธ์ธีรา ศรุติพงศ์โภคิน (เกิด 3 ธันวาคม พ.ศ. ...   \n",
       "2      พัทธ์ธีรา ศรุติพงศ์โภคิน (เกิด 3 ธันวาคม พ.ศ. ...   \n",
       "3      พัทธ์ธีรา ศรุติพงศ์โภคิน (เกิด 3 ธันวาคม พ.ศ. ...   \n",
       "4      คลีโอพัตราที่ 7 ฟิโลพาเธอร์ (กรีก: Κλεοπάτρα θ...   \n",
       "...                                                  ...   \n",
       "17080  นิยาย ชานะ นักรบเนตรอัคคี แต่งโดย ยาชิจิโร ทาค...   \n",
       "17081  ไบโอช็อก อินฟินิต (English: BioShock Infinite)...   \n",
       "17082  ยู ซึง-โฮเดบิวต์เมื่อปี 1999 กับผลงานโฆษณาของ ...   \n",
       "17083  กันเกิดเมื่อวันที่ 23 ตุลาคม พ.ศ. 2533 จังหวัด...   \n",
       "17084  รองศาสตราจารย์ หม่อมราชวงศ์สุขุมพันธุ์ บริพัตร...   \n",
       "\n",
       "                                                 answers  source  \n",
       "0      {'text': ['3 ธันวาคม พ.ศ. 2533'], 'answer_star...    iapp  \n",
       "1      {'text': ['อร'], 'answer_start': [], 'answer_e...    iapp  \n",
       "2      {'text': ['นักแสดงหญิงชาวไทย'], 'answer_start'...    iapp  \n",
       "3      {'text': ['ประเทศนิวซีแลนด์'], 'answer_start':...    iapp  \n",
       "4      {'text': ['ทอเลมีที่ 12 ออเลติส'], 'answer_sta...    iapp  \n",
       "...                                                  ...     ...  \n",
       "17080  {'text': ['22', '26'], 'answer_start': [], 'an...  tydiqa  \n",
       "17081  {'text': ['26 มีนาคม พ.ศ. 2556', '26 มีนาคม พ....  tydiqa  \n",
       "17082  {'text': ['ปี 1999', '1999'], 'answer_start': ...  tydiqa  \n",
       "17083  {'text': ['นางวรรณา อินทร์ใจเอื้อ', 'นางวรรณา ...  tydiqa  \n",
       "17084  {'text': ['22 กันยายน 2495', '22 กันยายน 2495'...  tydiqa  \n",
       "\n",
       "[17085 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.concat([iapp, thaiqa, xquad, tydiqa], ignore_index=True)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"data/01_prepared_merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgresearch39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
